"""
ONNX ëª¨ë¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
YOLOv8ê³¼ OSNetì„ ONNX í¬ë§·ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ë¡  ì†ë„ë¥¼ 3-5ë°° í–¥ìƒì‹œí‚µë‹ˆë‹¤.
"""

import torch
import torch.onnx
from ultralytics import YOLO
import torchreid
from torchvision import transforms
import onnx
import onnxruntime as ort
import numpy as np
from PIL import Image
import os


def convert_yolov8_to_onnx(model_path='yolov8n.pt', output_path='yolov8n.onnx', imgsz=640):
    """
    YOLOv8 ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜

    Args:
        model_path: YOLOv8 PyTorch ëª¨ë¸ ê²½ë¡œ
        output_path: ì¶œë ¥ ONNX ëª¨ë¸ ê²½ë¡œ
        imgsz: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 640)
    """
    print(f"\n{'='*60}")
    print("ğŸ”„ YOLOv8 â†’ ONNX ë³€í™˜ ì‹œì‘...")
    print(f"{'='*60}\n")

    try:
        # YOLOv8 ë¡œë“œ
        model = YOLO(model_path)

        # ONNXë¡œ ë³€í™˜ (Ultralytics ë‚´ì¥ ê¸°ëŠ¥ ì‚¬ìš©)
        model.export(
            format='onnx',
            imgsz=imgsz,
            simplify=True,  # ëª¨ë¸ ë‹¨ìˆœí™” (ì†ë„ í–¥ìƒ)
            opset=12,       # ONNX opset ë²„ì „
            dynamic=False   # ê³ ì • ì…ë ¥ í¬ê¸° (ë” ë¹ ë¦„)
        )

        # ìƒì„±ëœ íŒŒì¼ëª… í™•ì¸ (ultralyticsëŠ” ìë™ìœ¼ë¡œ ì´ë¦„ ìƒì„±)
        auto_generated_path = model_path.replace('.pt', '.onnx')

        # ì›í•˜ëŠ” ê²½ë¡œë¡œ ì´ë™
        if auto_generated_path != output_path and os.path.exists(auto_generated_path):
            os.rename(auto_generated_path, output_path)

        # ê²€ì¦
        if os.path.exists(output_path):
            onnx_model = onnx.load(output_path)
            onnx.checker.check_model(onnx_model)

            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            print(f"âœ… YOLOv8 ONNX ë³€í™˜ ì™„ë£Œ!")
            print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
            print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")

            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            test_onnx_yolo(output_path, imgsz)

            return output_path
        else:
            print(f"âŒ ONNX íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {output_path}")
            return None

    except Exception as e:
        print(f"âŒ YOLOv8 ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def convert_osnet_to_onnx(output_path='osnet_x1_0.onnx'):
    """
    OSNet ReID ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜

    Args:
        output_path: ì¶œë ¥ ONNX ëª¨ë¸ ê²½ë¡œ
    """
    print(f"\n{'='*60}")
    print("ğŸ”„ OSNet ReID â†’ ONNX ë³€í™˜ ì‹œì‘...")
    print(f"{'='*60}\n")

    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"

        # OSNet ëª¨ë¸ ë¡œë“œ
        print("OSNet ëª¨ë¸ ë¡œë”© ì¤‘...")
        reid_model = torchreid.models.build_model(
            name='osnet_x1_0',
            num_classes=1000,
            loss='softmax',
            pretrained=True
        )
        reid_model.eval()
        reid_model = reid_model.to(device)

        # ë”ë¯¸ ì…ë ¥ ìƒì„± (OSNet ì…ë ¥ í¬ê¸°: 256x128)
        dummy_input = torch.randn(1, 3, 256, 128).to(device)

        # ONNXë¡œ ë³€í™˜
        print("ONNX ë³€í™˜ ì¤‘...")
        torch.onnx.export(
            reid_model,
            dummy_input,
            output_path,
            export_params=True,
            opset_version=12,
            do_constant_folding=True,  # ìµœì í™”
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )

        # ê²€ì¦
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)

        print(f"\nâœ… OSNet ONNX ë³€í™˜ ì™„ë£Œ!")
        print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
        print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")

        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        test_onnx_osnet(output_path)

        return output_path

    except Exception as e:
        print(f"âŒ OSNet ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def test_onnx_yolo(onnx_path, imgsz=640, iterations=50):
    """ONNX YOLOv8 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    import time

    print(f"\nğŸ“Š YOLOv8 ONNX ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘... ({iterations}íšŒ)")

    # ONNX Runtime ì„¸ì…˜ ìƒì„±
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']
    session = ort.InferenceSession(onnx_path, providers=providers)

    # ë”ë¯¸ ì…ë ¥ ìƒì„±
    dummy_input = np.random.randn(1, 3, imgsz, imgsz).astype(np.float32)

    # Warm-up
    for _ in range(5):
        session.run(None, {session.get_inputs()[0].name: dummy_input})

    # ì„±ëŠ¥ ì¸¡ì •
    times = []
    for _ in range(iterations):
        start = time.time()
        session.run(None, {session.get_inputs()[0].name: dummy_input})
        times.append(time.time() - start)

    avg_time = np.mean(times) * 1000  # ms
    fps = 1000 / avg_time

    print(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
    print(f"   ì˜ˆìƒ FPS: {fps:.1f}")
    print(f"   ì‚¬ìš© Provider: {session.get_providers()[0]}")


def test_onnx_osnet(onnx_path, iterations=100):
    """ONNX OSNet ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    import time

    print(f"\nğŸ“Š OSNet ONNX ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘... ({iterations}íšŒ)")

    # ONNX Runtime ì„¸ì…˜ ìƒì„±
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']
    session = ort.InferenceSession(onnx_path, providers=providers)

    # ë”ë¯¸ ì…ë ¥ ìƒì„±
    dummy_input = np.random.randn(1, 3, 256, 128).astype(np.float32)

    # Warm-up
    for _ in range(5):
        session.run(None, {'input': dummy_input})

    # ì„±ëŠ¥ ì¸¡ì •
    times = []
    for _ in range(iterations):
        start = time.time()
        session.run(None, {'input': dummy_input})
        times.append(time.time() - start)

    avg_time = np.mean(times) * 1000  # ms

    print(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
    print(f"   ì´ˆë‹¹ ì²˜ë¦¬ ê°€ëŠ¥: {1000/avg_time:.0f} ëª…")
    print(f"   ì‚¬ìš© Provider: {session.get_providers()[0]}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "="*60)
    print("ğŸš€ ONNX ëª¨ë¸ ë³€í™˜ê¸°")
    print("="*60)
    print("\nì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” YOLOv8ê³¼ OSNetì„ ONNXë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
    print("ONNX ë³€í™˜ìœ¼ë¡œ 3-5ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n")

    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if torch.cuda.is_available():
        print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  CPU ëª¨ë“œ (GPU ì‚¬ìš© ë¶ˆê°€)")

    print("\n" + "-"*60 + "\n")

    # 1. YOLOv8 ë³€í™˜
    yolo_onnx = convert_yolov8_to_onnx(
        model_path='yolov8n.pt',
        output_path='yolov8n.onnx',
        imgsz=640
    )

    # 2. OSNet ë³€í™˜
    osnet_onnx = convert_osnet_to_onnx(
        output_path='osnet_x1_0.onnx'
    )

    # ìµœì¢… ê²°ê³¼
    print("\n" + "="*60)
    print("ğŸ“¦ ë³€í™˜ ì™„ë£Œ ìš”ì•½")
    print("="*60)

    if yolo_onnx and os.path.exists(yolo_onnx):
        print(f"âœ… YOLOv8 ONNX: {yolo_onnx}")
    else:
        print("âŒ YOLOv8 ONNX ë³€í™˜ ì‹¤íŒ¨")

    if osnet_onnx and os.path.exists(osnet_onnx):
        print(f"âœ… OSNet ONNX: {osnet_onnx}")
    else:
        print("âŒ OSNet ONNX ë³€í™˜ ì‹¤íŒ¨")

    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. app_optimized.pyë¡œ ìµœì í™”ëœ ì•± ì‹¤í–‰")
    print("   2. streamlit run app_optimized.py")
    print("\n" + "="*60 + "\n")


if __name__ == "__main__":
    main()
